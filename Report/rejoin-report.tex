% should be double-blind (add anonymous to documentclass before review)
% 12 pages + references
%

\documentclass[sigconf,10pt,preprint]{acmart}

%\usepackage{booktabs} % For formal tables
\usepackage{tikz}
\usetikzlibrary{arrows,calc,fit,backgrounds,positioning}
%\usepackage{adjustbox}
%\usepackage{subfigure}
%\usepackage{caption}
%\usepackage{subcaption}
%\usepackage{algorithmic}
%\usepackage{algorithmicx}
%\usepackage{algpseudocode}

% Copyright
%\setcopyright{none}
\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
%\acmDOI{10.475/123_4}

% ISBN
%\acmISBN{123-4567-24-567/08/06}


\acmYear{2019}
\copyrightyear{2016=9}

%\acmPrice{15.00}

%\acmSubmissionID{123-A12-B3}

\newcommand{\lsem}{\mbox{$\lbrack\!\lbrack$}}
\newcommand{\rsem}{\mbox{$\rbrack\!\rbrack$}}

\begin{document}

\title{Reproducing ReJOIN;
a learned join ordering optimizer}

\author{Calliope Kostopoulou}
\affiliation{%
  \department{Department of Informatics and Telecommunications}
  \institution{University of Athens}
  \city{Athens}
  \country{Greece}
}
\email{kelkost@di.uoa.gr}
\author{Antonis Mandamadiotis}
\orcid{0000-0001-7437-410X}
\affiliation{%
  \department{Department of Informatics and Telecommunications}
  \institution{University of Athens}
  \city{Athens}
  \country{Greece}
}
\email{antonis@di.uoa.gr}

\renewcommand{\shortauthors}{C.Kostopoulou, A.Mandamadiotis }
\renewcommand{\shorttitle}{ReJoin}

\begin{abstract}
Bubbles
\end{abstract}

\begin{CCSXML}
  <ccs2012>
    <concept>
      <concept_id>10011007.10011006.10011008.10011009.10011016</concept_id>
      <concept_desc></concept_desc>
      <concept_significance>500</concept_significance>
    </concept>
    <concept>
      <concept_id>10011007.10011006.10011008.10011024.10011033</concept_id>
      <concept_desc></concept_desc>
      <concept_significance>500</concept_significance>
    </concept>
    <concept>
      <concept_id>10011007.10011006.10011008.10011009.10010177</concept_id>
      <concept_desc></concept_desc>
      <concept_significance>300</concept_significance>
    </concept>
\end{CCSXML}

\ccsdesc[500]{bubbles bubbles~Bubbles}

\keywords{Reinforcement Learning, Join Enumeration, query optimization}

\maketitle

\section{Paper Overview}
\label{paper-overview}

Overview of the paper

\section{Overview of classes and implementation}
\label{implementation-overview}
The classes we created for our implementation are the following:
Database: used to get/send data to the database
Some methods for this class include connecting to the database, retrieving queries by id/filename, retrieving groups of queries, getting cost estimation,planning/execution times and the whole query reconstruction process.

\subsection{Environment}
Environment: the basic class defining how the reinforcement learning agent takes actions and how the states change
The environment class is found in all reinforcement learning frameworks. We firstly started designing an OpenAI gym, but then switched to a tensorforce environment. The functions used in different environments are almost the same, following a common logic to solve the same problem. The most important functions included are:
the reset() function where the environment initializes the actions/states at the start of each episode
the execute(action) function where the agent has taken a specific action and we interact with the environment according to that action, updating our state and our possible actions.
We have included a lot of helper functions like getting a reward for a final ordering, getting valid actions for the current state, updating the state, joining two subtrees in order to produce a single one.

\subsection{State Representation}
StateVector: the class responsible for transforming a query to the corresponding structures as described the ReJOIN paper.
The 3 structures described in the paper are the following:
tree structure: an rxr matrix where each row represents a subtree containing 1 when the column corresponding to that relation is including in that subtree, or 0 if it’s not. Initially each row will contain at most 1 relations as there are no joins yet. 
join predicates: an rxr matrix providing the conditions allowing joins to happen. For example if table A can be joined with table B then a value of 1 will appear in the corresponding location [0][1].
column predicates: a vector of length equal to the total number of columns in the database, holding information about the attributes that are present to the query.

\subsection{Implementation Details}
Implementation details:
Our whole code gets executed by the file main.py where:
First there is a parsing of the parameters to be used in the specific execution,
the Environment is initialized,
we define our network’s architecture,
the Proximal Policy Optimization agent which is included in the tensorflow agent as PPOAgent is initialized with the proper parameters.
Finally after the training completes we generate some useful plots that help us gain an insight to the results of the episodes.
The neural network included in the architecture is responsible for the choices taken by the agent at each step. The network takes as inputs our 3 vectors describing our state (tree,join predicates, column predicates) which get passed into 2 hidden layers with size=128, which result to the final action layer with size equal to action space. With this way the last layer contains probabilities of each action to be selected.

\subsection{Action Space}

Originally the authors propose using an action space that contains each pair for 1 to r. For example they include the pair (1,2) and (2,1). In order to reduce the size of the action space we decided to remove these duplicate pairs as they correspond to the same actions. However,  the action space was still large containing (r*r -r)/2 where in our case when r=39 this number is equal to 741 possible actions. Typically in reinforcement learning problems the agent only has to decide between a much smaller number of actions. So that brought us upon the problem of a large action space giving us bad results. For example it would be technically impossible for our agent to explore a reasonable amount of possible actions in a reasonable number of episodes. So, to further reduce the size of the action space, we decided to take into consideration the table relationships, producing a set of actions equal to the total number of possible joins. We found out that the possible joins for the tables in our database is equal to 22.

\section{Experiments}
\label{experiments}



\section{Conclusions}
\label{conclusions}


\bibliographystyle{ACM-Reference-Format}
\bibliography{rejoin}

\end{document}

\begin{figure}
  \centering
  \resizebox{0.45\textwidth}{!}{%
    \input{diagrams/}}
  \caption{The transformed graph of $\mathit{fact}$}
  \label{fact-trans}
\end{figure}


\begin{align*}
  \lsem\textsc{Call}_i\rsem\ \langle t, d \rangle & =  \langle i:t, d \rangle
\end{align*}


\begin{itemize}
  \item ..
  \item ..
\end{itemize}
